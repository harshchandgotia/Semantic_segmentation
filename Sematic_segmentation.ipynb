{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T16:01:57.232928Z",
     "start_time": "2024-10-14T16:01:57.077623Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 126] The specified module could not be found. Error loading \"C:\\Users\\chand\\anaconda3\\envs\\my_env\\Lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env\\Lib\\site-packages\\torch\\__init__.py:148\u001b[0m\n\u001b[0;32m    146\u001b[0m                 err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(ctypes\u001b[38;5;241m.\u001b[39mget_last_error())\n\u001b[0;32m    147\u001b[0m                 err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 148\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    150\u001b[0m     kernel32\u001b[38;5;241m.\u001b[39mSetErrorMode(prev_error_mode)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_preload_cuda_deps\u001b[39m(lib_folder, lib_name):\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 126] The specified module could not be found. Error loading \"C:\\Users\\chand\\anaconda3\\envs\\my_env\\Lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from sematic_dataloader import SegmentationDataset\n",
    "from Model import SegNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d97831a63a7eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize image if needed\n",
    "    transforms.ToTensor(),          # Convert image to PyTorch tensor\n",
    "])\n",
    "\n",
    "label_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize label if needed\n",
    "    transforms.ToTensor(),          # Convert label to tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f28b1662c374c2b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T11:53:42.400345Z",
     "start_time": "2024-09-09T11:53:42.388535Z"
    }
   },
   "outputs": [],
   "source": [
    "image_dir = 'data/png/train'\n",
    "label_dir = 'data/png/train_labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "825ff8494131d8fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T11:53:42.411293Z",
     "start_time": "2024-09-09T11:53:42.400345Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = SegmentationDataset(image_dir=image_dir, label_dir=label_dir, transform= image_transforms, target_transform= label_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbf335c5214f1e11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T11:53:42.420073Z",
     "start_time": "2024-09-09T11:53:42.411293Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db8ed38cf1b84537",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T11:53:42.428995Z",
     "start_time": "2024-09-09T11:53:42.420073Z"
    }
   },
   "outputs": [],
   "source": [
    "val_image_dir = 'data/png/val'\n",
    "val_label_dir = 'data/png/val_labels'\n",
    "test_image_dir = 'data/png/test'\n",
    "test_label_dir = 'data/png/test_labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54cd1c7666a5c50b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T11:53:42.438061Z",
     "start_time": "2024-09-09T11:53:42.428995Z"
    }
   },
   "outputs": [],
   "source": [
    "val_data = SegmentationDataset(image_dir=val_image_dir, label_dir=val_label_dir, transform= image_transforms, target_transform= label_transforms)\n",
    "val_dataloader = DataLoader(val_data, batch_size=16, shuffle=True)\n",
    "test_data = SegmentationDataset(image_dir=test_image_dir, label_dir=test_label_dir, transform= label_transforms, target_transform= label_transforms)\n",
    "test_dataloader = DataLoader(test_data, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63334061673fba2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T11:53:42.463332Z",
     "start_time": "2024-09-09T11:53:42.438061Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = SegNet()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3ab7b0a4285e44a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T11:53:42.473576Z",
     "start_time": "2024-09-09T11:53:42.463332Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a58f01c478c9d408",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T11:53:42.640465Z",
     "start_time": "2024-09-09T11:53:42.473576Z"
    }
   },
   "outputs": [],
   "source": [
    "model = SegNet()#.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58f88e7b6d02b4c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T11:53:42.646358Z",
     "start_time": "2024-09-09T11:53:42.640465Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SegNet(\n",
       "  (enc0): EncoderBlock(\n",
       "    (layers): ModuleList(\n",
       "      (0): ConvReLU(\n",
       "        (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): ConvReLU(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (enc1): EncoderBlock(\n",
       "    (layers): ModuleList(\n",
       "      (0): ConvReLU(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): ConvReLU(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (enc2): EncoderBlock(\n",
       "    (layers): ModuleList(\n",
       "      (0): ConvReLU(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1-2): 2 x ConvReLU(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (enc3): EncoderBlock(\n",
       "    (layers): ModuleList(\n",
       "      (0): ConvReLU(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1-2): 2 x ConvReLU(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (bottleneck_enc): EncoderBlock(\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x ConvReLU(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (bottleneck_dec): DecoderBlock(\n",
       "    (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x ConvReLU(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dec0): DecoderBlock(\n",
       "    (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x ConvReLU(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ConvReLU(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dec1): DecoderBlock(\n",
       "    (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x ConvReLU(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ConvReLU(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dec2): DecoderBlock(\n",
       "    (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "    (layers): ModuleList(\n",
       "      (0): ConvReLU(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): ConvReLU(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dec3): DecoderBlock(\n",
       "    (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "    (layers): ModuleList(\n",
       "      (0): ConvReLU(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8083cf0a28d14295",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T11:53:42.656418Z",
     "start_time": "2024-09-09T11:53:42.646358Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x0000018981D9F4C0>\n"
     ]
    }
   ],
   "source": [
    "print(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb615a66dbb20d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93aad8a62ffb9c1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T11:53:42.664895Z",
     "start_time": "2024-09-09T11:53:42.656418Z"
    }
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# model.eval()  # Set the model to evaluation mode\n",
    "# \n",
    "# # Optionally, load a pretrained model (if available)\n",
    "# # model.load_state_dict(torch.load('path_to_pretrained_model.pth'))\n",
    "# \n",
    "# # Define the image preprocessing steps\n",
    "# preprocess = transforms.Compose([\n",
    "#     transforms.Resize((256, 256)),  # Resize to match the input size expected by the model\n",
    "#     transforms.ToTensor(),  # Convert image to PyTorch tensor\n",
    "#     #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalization (optional)\n",
    "# ])\n",
    "# \n",
    "# # Load and preprocess the image\n",
    "# image_path = 'data/png/train/22678915_15.png'\n",
    "# input_image = Image.open(image_path).convert('RGB')\n",
    "# input_tensor = preprocess(input_image).unsqueeze(0)#.to(device)  # Add batch dimension\n",
    "# \n",
    "# # Perform a forward pass with the model\n",
    "# with torch.no_grad():  # Disable gradient computation for inference\n",
    "#     output = model(input_tensor)\n",
    "# \n",
    "# # Post-process the output (e.g., apply sigmoid for binary segmentation)\n",
    "# output = torch.sigmoid(output)\n",
    "# \n",
    "# # Convert output to a numpy array and threshold it for binary segmentation\n",
    "# output_np = output.squeeze().cpu().numpy()  # Remove batch and channel dimensions\n",
    "# binary_mask = (output_np > 0.5).astype('uint8')  # Thresholding to get a binary mask\n",
    "# \n",
    "# # Visualize or save the result\n",
    "# cv2.imshow('Segmentation Mask', binary_mask * 255)  # Multiply by 255 to convert to a visible grayscale image\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be19ab7bd289542c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T11:57:09.397277Z",
     "start_time": "2024-09-09T11:53:42.664895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0\n",
      "Epoch 2, Loss: 0.0\n",
      "Epoch 3, Loss: 0.0\n",
      "Epoch 4, Loss: 0.0\n",
      "Epoch 5, Loss: 0.0\n",
      "Epoch 6, Loss: 0.0\n",
      "Epoch 7, Loss: 0.0\n",
      "Epoch 8, Loss: 0.0\n",
      "Epoch 9, Loss: 0.0\n",
      "Epoch 10, Loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "model = SegNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, masks in train_dataloader:\n",
    "        inputs, masks = inputs.to(device), masks.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a05d5925d329d1f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T11:57:09.489754Z",
     "start_time": "2024-09-09T11:57:09.397277Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(model, image_path, transform, device):\n",
    "    model.eval()\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "    return output.squeeze(0).cpu()\n",
    "\n",
    "image_path = 'data/png/test/23729035_15.png'\n",
    "predicted_mask = predict(model, image_path, image_transforms, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "885a1aad7c6140ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T11:57:09.499600Z",
     "start_time": "2024-09-09T11:57:09.489754Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2443,  0.1383,  0.0384,  ...,  0.0799, -0.0249,  0.0603],\n",
       "         [ 0.1279, -0.0193,  0.0870,  ..., -0.1070,  0.1516,  0.2231],\n",
       "         [-0.0990, -0.0179, -0.2341,  ..., -0.0653,  0.1620,  0.1267],\n",
       "         ...,\n",
       "         [-0.1374, -0.3085,  0.1926,  ..., -0.0806,  0.1750,  0.0166],\n",
       "         [-0.2028, -0.2144,  0.2699,  ..., -0.1293,  0.0052,  0.0779],\n",
       "         [ 0.0544, -0.0712, -0.2443,  ...,  0.1473,  0.2050,  0.0110]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e990761ba5cebc2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T11:57:09.516874Z",
     "start_time": "2024-09-09T11:57:09.499600Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.ToPILImage()\n",
    "img = transform(predicted_mask)\n",
    "\n",
    "# display the PIL image\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac91bdc9d6bd7f90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T12:00:37.489795Z",
     "start_time": "2024-09-09T11:57:09.516874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.0, Validation Loss: 0.0\n",
      "Epoch 2, Train Loss: 0.0, Validation Loss: 0.0\n",
      "Epoch 3, Train Loss: 0.0, Validation Loss: 0.0\n",
      "Epoch 4, Train Loss: 0.0, Validation Loss: 0.0\n",
      "Epoch 5, Train Loss: 0.0, Validation Loss: 0.0\n",
      "Epoch 6, Train Loss: 0.0, Validation Loss: 0.0\n",
      "Epoch 7, Train Loss: 0.0, Validation Loss: 0.0\n",
      "Epoch 8, Train Loss: 0.0, Validation Loss: 0.0\n",
      "Epoch 9, Train Loss: 0.0, Validation Loss: 0.0\n",
      "Epoch 10, Train Loss: 0.0, Validation Loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, masks in dataloader:\n",
    "            inputs, masks = inputs.to(device), masks.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, masks)\n",
    "            val_loss += loss.item()\n",
    "    return val_loss / len(dataloader)\n",
    "\n",
    "#val_dataloader = DataLoader(validation_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training step (as before)\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, masks in train_dataloader:\n",
    "        inputs, masks = inputs.to(device), masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    train_loss = running_loss / len(train_dataloader)\n",
    "    \n",
    "    # Validation step\n",
    "    val_loss = evaluate(model, val_dataloader, criterion, device)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss}, Validation Loss: {val_loss}\")\n",
    "    \n",
    "    # Save the model if validation loss decreases\n",
    "    # torch.save(model.state_dict(), f\"model_epoch_{epoch+1}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb236918549e98ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T12:00:37.496617Z",
     "start_time": "2024-09-09T12:00:37.489795Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SegNet(\n",
       "  (enc0): EncoderBlock(\n",
       "    (layers): ModuleList(\n",
       "      (0): ConvReLU(\n",
       "        (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): ConvReLU(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (enc1): EncoderBlock(\n",
       "    (layers): ModuleList(\n",
       "      (0): ConvReLU(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): ConvReLU(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (enc2): EncoderBlock(\n",
       "    (layers): ModuleList(\n",
       "      (0): ConvReLU(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1-2): 2 x ConvReLU(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (enc3): EncoderBlock(\n",
       "    (layers): ModuleList(\n",
       "      (0): ConvReLU(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1-2): 2 x ConvReLU(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (bottleneck_enc): EncoderBlock(\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x ConvReLU(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (bottleneck_dec): DecoderBlock(\n",
       "    (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x ConvReLU(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dec0): DecoderBlock(\n",
       "    (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x ConvReLU(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ConvReLU(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dec1): DecoderBlock(\n",
       "    (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x ConvReLU(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ConvReLU(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dec2): DecoderBlock(\n",
       "    (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "    (layers): ModuleList(\n",
       "      (0): ConvReLU(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): ConvReLU(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dec3): DecoderBlock(\n",
       "    (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "    (layers): ModuleList(\n",
       "      (0): ConvReLU(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9d0d1b7eefa241c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T12:00:37.559602Z",
     "start_time": "2024-09-09T12:00:37.496617Z"
    }
   },
   "outputs": [],
   "source": [
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "image = image_transforms(image).unsqueeze(0).to(device)\n",
    "with torch.no_grad():\n",
    "    output = model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f58f3ef254dc43e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T12:00:37.638252Z",
     "start_time": "2024-09-09T12:00:37.559602Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.1331,  0.0955,  0.0235,  ..., -0.0431,  0.1252,  0.0738],\n",
       "          [ 0.1198,  0.1264,  0.1045,  ..., -0.1557,  0.1274,  0.1604],\n",
       "          [-0.1118, -0.0384, -0.1636,  ..., -0.0861,  0.1426,  0.1664],\n",
       "          ...,\n",
       "          [-0.2900, -0.2144,  0.0970,  ..., -0.1159,  0.0553, -0.0330],\n",
       "          [-0.1346, -0.2411,  0.4362,  ..., -0.0933, -0.0568,  0.1016],\n",
       "          [ 0.0916,  0.0226, -0.1634,  ...,  0.1570,  0.1064,  0.0378]]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
